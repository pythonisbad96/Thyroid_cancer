# ğŸ§  ê°‘ìƒì„ ì•” ì§„ë‹¨ ë¶„ë¥˜ AI í”„ë¡œì íŠ¸

> ì˜ë£Œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°‘ìƒì„ ì•” ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.  
> ë‹¤ì–‘í•œ ëª¨ë¸ í•™ìŠµê³¼ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹, ì•™ìƒë¸”ì„ í†µí•´ F1-scoreë¥¼ ê·¹ëŒ€í™”í•˜ì˜€ìŠµë‹ˆë‹¤.

---

## ğŸ“Œ í”„ë¡œì íŠ¸ ê°œìš”

- **ëª©í‘œ**: í™˜ìì˜ ë‹¤ì–‘í•œ ì˜í•™ì  ì§€í‘œ(TSH, T3, T4 ë“±)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°‘ìƒì„ ì•” ì—¬ë¶€(`Cancer`)ë¥¼ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ ê°œë°œ
- **ì ‘ê·¼ ë°©ë²•**: ë°ì´í„° ì „ì²˜ë¦¬ â†’ ëª¨ë¸ë³„ íŠœë‹ â†’ ì•™ìƒë¸” â†’ Threshold ì¡°ì • â†’ ì„±ëŠ¥ ì‹œê°í™”
- **ì‚¬ìš© ê¸°ìˆ **: Python, Scikit-learn, XGBoost, CatBoost, LightGBM, Matplotlib

---

## ğŸ§¾ ë°ì´í„° ì •ë³´

- **Train.csv**: í•™ìŠµ ë° ê²€ì¦ ë°ì´í„°
- **Test.csv**: ì˜ˆì¸¡ìš© í…ŒìŠ¤íŠ¸ ë°ì´í„°
- **Sample_submission.csv**: ì œì¶œ í˜•ì‹ í…œí”Œë¦¿

---

## ğŸ”§ ì „ì²˜ë¦¬ ë° íŠ¹ì„± ì„ íƒ

- Label Encodingì„ í†µí•´ ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬
- `Gender`, `Smoke`, `Weight_Risk`, `Diabetes`ëŠ” feature ì¤‘ìš”ë„ê°€ ë‚®ì•„ ì œê±°
- í•™ìŠµ/ê²€ì¦ ì„¸íŠ¸ë¥¼ 80:20 ë¹„ìœ¨ë¡œ ë¶„ë¦¬ (`stratify` ì ìš©)

---

## ğŸ¤– ëª¨ë¸ë§ ë° ì•™ìƒë¸”

### ğŸ¯ XGBoost (íŠœë‹ í¬í•¨)

```python
from xgboost import XGBClassifier
from sklearn.model_selection import RandomizedSearchCV

xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
param_grid = {
    'max_depth': [6],
    'learning_rate': [0.01, 0.1],
    'n_estimators': [100, 300],
    'scale_pos_weight': [1, 7.3, 15]
}
rs_xgb = RandomizedSearchCV(xgb, param_grid, scoring='f1', n_iter=10, cv=5)
rs_xgb.fit(X_train, y_train)
best_xgb = rs_xgb.best_estimator_
```

---

### ğŸ§© Soft Voting ì•™ìƒë¸”

```python
from sklearn.ensemble import VotingClassifier

voting_model = VotingClassifier(
    estimators=[('xgb', best_xgb), ('cat', best_cat), ('lgb', lgb_model)],
    voting='soft'
)
voting_model.fit(X_train, y_train)
```

---

### ğŸ” Threshold íŠœë‹

```python
from sklearn.metrics import f1_score
import numpy as np

proba = voting_model.predict_proba(X_val)[:, 1]
thresholds = np.arange(0.30, 0.71, 0.01)
f1_scores = [f1_score(y_val, proba > t) for t in thresholds]
best_thresh = thresholds[np.argmax(f1_scores)]
```

---

## ğŸ“ˆ ê²°ê³¼ ë° í‰ê°€

- F1-score ê¸°ì¤€ ìµœì  threshold ì„ íƒ
- confusion matrix, classification report ì¶œë ¥
- ê²°ê³¼ ì œì¶œ íŒŒì¼ ìƒì„±: `submit_voting_xgbtuned.csv`

---

## ğŸ›  ì‚¬ìš©ëœ íŒ¨í‚¤ì§€

```text
pandas, scikit-learn, xgboost, catboost, lightgbm, matplotlib, numpy
```

---

## ğŸ“ í”„ë¡œì íŠ¸ íšŒê³ 

- í´ë˜ìŠ¤ ë¶ˆê· í˜• ëŒ€ì‘ ì „ëµì˜ ì¤‘ìš”ì„± í•™ìŠµ
- ë‹¨ì¼ ëª¨ë¸ë³´ë‹¤ ì•™ìƒë¸” + threshold ìµœì í™”ì˜ ì„±ëŠ¥ ìš°ìœ„ í™•ì¸
- í–¥í›„ SHAP, SMOTE ì¶”ê°€ ì ìš© ì˜ˆì •

---

## ğŸ”— ì°¸ê³  ë§í¬

- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [CatBoost Documentation](https://catboost.ai/)
- [LightGBM Documentation](https://lightgbm.readthedocs.io/)

